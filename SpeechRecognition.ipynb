{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1e5124",
   "metadata": {},
   "source": [
    "## Speech Recognition\n",
    "speech recognition incorportes the field of computer science and linguistics to indentify the spoken words and convert them into text it allows computers to understand human language\n",
    "\n",
    "    Speech is first converted from physical sound to electrical energy to digital data(using analog to digital converter) \n",
    "    and then to text(using algorithms like Neural Networks or Hidden markov model)\n",
    "\n",
    "There are Multiple speech recognition modules which will provide different functionalities, some commonly used pacakges are:\n",
    "\n",
    "-  Apiai- Includes natural language processsing for identifying a speakers intent\n",
    "-  Googlecloudspeech- offeres basic speech to text conversion\n",
    "-  Speech Recognition- Provides simple audio processing and microphone accessibility   \n",
    " \n",
    " ### Audio:\n",
    " if you will see the image of an audio recording you will see multiple line and that could be arrange as per the timeline\n",
    "-  Each channel in a multi-channel audio file represents a distinct audio signal. For example, if you have a 16-instruments playing at differnent mic the  audio file, you have 16 separate audio signals\n",
    "-  The height of the waveform at any given point represents the amplitude of the audio signal at that moment in time. Higher values indicate louder sounds.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7cef699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\rashi\\anaconda\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\rashi\\anaconda\\lib\\site-packages (from SpeechRecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rashi\\anaconda\\lib\\site-packages (from SpeechRecognition) (4.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rashi\\anaconda\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rashi\\anaconda\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rashi\\anaconda\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rashi\\anaconda\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.25.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#installing speechRecognition\n",
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c2a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84480773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "#means py to text 3  ,this package is going to help us to read the text back to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d258a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=sr.Recognizer()\n",
    "#function to convert text to speech\n",
    "def SpeakText(data):\n",
    "    #initializing the engine\n",
    "    engine=pyttsx3.init() \n",
    "    engine.say(data)\n",
    "    engine.runAndWait()\n",
    "SpeakText(\"My name is Rohan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9895f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Microphone in module speech_recognition:\n",
      "\n",
      "class Microphone(AudioSource)\n",
      " |  Microphone(device_index=None, sample_rate=None, chunk_size=1024)\n",
      " |  \n",
      " |  Creates a new ``Microphone`` instance, which represents a physical microphone on the computer. Subclass of ``AudioSource``.\n",
      " |  \n",
      " |  This will throw an ``AttributeError`` if you don't have PyAudio 0.2.11 or later installed.\n",
      " |  \n",
      " |  If ``device_index`` is unspecified or ``None``, the default microphone is used as the audio source. Otherwise, ``device_index`` should be the index of the device to use for audio input.\n",
      " |  \n",
      " |  A device index is an integer between 0 and ``pyaudio.get_device_count() - 1`` (assume we have used ``import pyaudio`` beforehand) inclusive. It represents an audio device such as a microphone or speaker. See the `PyAudio documentation <http://people.csail.mit.edu/hubert/pyaudio/docs/>`__ for more details.\n",
      " |  \n",
      " |  The microphone audio is recorded in chunks of ``chunk_size`` samples, at a rate of ``sample_rate`` samples per second (Hertz). If not specified, the value of ``sample_rate`` is determined automatically from the system's microphone settings.\n",
      " |  \n",
      " |  Higher ``sample_rate`` values result in better audio quality, but also more bandwidth (and therefore, slower recognition). Additionally, some CPUs, such as those in older Raspberry Pi models, can't keep up if this value is too high.\n",
      " |  \n",
      " |  Higher ``chunk_size`` values help avoid triggering on rapidly changing ambient noise, but also makes detection less sensitive. This value, generally, should be left at its default.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Microphone\n",
      " |      AudioSource\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_value, traceback)\n",
      " |  \n",
      " |  __init__(self, device_index=None, sample_rate=None, chunk_size=1024)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  get_pyaudio()\n",
      " |      Imports the pyaudio module and checks its version. Throws exceptions if pyaudio can't be found or a wrong version is installed\n",
      " |  \n",
      " |  list_microphone_names()\n",
      " |      Returns a list of the names of all available microphones. For microphones where the name can't be retrieved, the list entry contains ``None`` instead.\n",
      " |      \n",
      " |      The index of each microphone's name in the returned list is the same as its device index when creating a ``Microphone`` instance - if you want to use the microphone at index 3 in the returned list, use ``Microphone(device_index=3)``.\n",
      " |  \n",
      " |  list_working_microphones()\n",
      " |      Returns a dictionary mapping device indices to microphone names, for microphones that are currently hearing sounds. When using this function, ensure that your microphone is unmuted and make some noise at it to ensure it will be detected as working.\n",
      " |      \n",
      " |      Each key in the returned dictionary can be passed to the ``Microphone`` constructor to use that microphone. For example, if the return value is ``{3: \"HDA Intel PCH: ALC3232 Analog (hw:1,0)\"}``, you can do ``Microphone(device_index=3)`` to use that microphone.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  MicrophoneStream = <class 'speech_recognition.Microphone.MicrophoneStr...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from AudioSource:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sr.Microphone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33032a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\rashi\\anaconda\\lib\\site-packages (0.2.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd712af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sr.Microphone() as source2:\n",
    "    print(\"Please sit in a quite area so that it could recognise your words\")\n",
    "    r.adjust_for_ambient_noise(source2,duration=2)\n",
    "    #This line makes the recognizer listen to the ambient noise \n",
    "    #for 2 seconds and adjusts the threshold for detecting speech based on this noise level.\n",
    "    #This helps in distinguishing speech from background noise.\n",
    "    print(\"Calibrated,now speak.....\")\n",
    "    audio=r.listen(source2)\n",
    "    try:\n",
    "        Mytext=r.recognize_google(audio)\n",
    "        print(f\"You said -- \\\"{Mytext.lower()}\\\"\")\n",
    "        said=f\"You said  {Mytext}\"\n",
    "        SpeakText(said)\n",
    "        #SpeakText(Mytext)\n",
    "    \n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sorry unable to hear you, there is to much disturbence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018fbe2",
   "metadata": {},
   "source": [
    "### Opening an webpage using speech recognition\n",
    "First we have to declare the path of the chrome so that it could open our chrom to perfrom the task given by the userthe we could do the same thing all over again to recognize the word of the user and then launch it on the app whos path is been given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3307c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------This dose exists------\n",
      "wait for the system to get the hold of the surrounding sound.\n",
      "Now it's ready!\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23452\\1817064200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0maudio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#taking input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcommand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m#now intializing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"You have said \\\"{command}\\\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\speech_recognition\\recognizers\\google.py\u001b[0m in \u001b[0;36mrecognize_legacy\u001b[1;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mshow_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwith_confidence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     )\n\u001b[1;32m--> 263\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\speech_recognition\\recognizers\\google.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, response_text)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse_text\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mactual_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_all\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\speech_recognition\\recognizers\\google.py\u001b[0m in \u001b[0;36mconvert_to_result\u001b[1;34m(response_text)\u001b[0m\n\u001b[0;32m    181\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import webbrowser as web\n",
    "import os\n",
    "if __name__==\"__main__\":\n",
    "    path =r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\"\n",
    "    r=sr.Recognizer()\n",
    "    if not os.path.exists(path):\n",
    "        print(\"------This dosen't exists------\")\n",
    "    else:\n",
    "        print(\"------This dose exists------\")\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"wait for the system to get the hold of the surrounding sound.\")   \n",
    "        r.adjust_for_ambient_noise(source,duration=5)\n",
    "        #adjusting the sound \n",
    "        print(\"Now it's ready!\")\n",
    "        audio=r.listen(source)\n",
    "        #taking input\n",
    "        command=r.recognize_google(audio)\n",
    "        #now intializing\n",
    "        print(f\"You have said \\\"{command}\\\"\")\n",
    "        try:\n",
    "            if not command.startswith(('http://', 'https://')):\n",
    "                command=f\"https://www.google.com/search?q=\"\n",
    "            web.get(path).open(command) \n",
    "            \n",
    "            # this command is used to open chrome with the help of webbrowser and open command is used to search particular content given\n",
    "        except Exception as e:\n",
    "            print(\"error\"+str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
